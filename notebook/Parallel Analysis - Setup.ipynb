{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head>\n",
    "\n",
    "\n",
    "<!-- Load require.js. Delete this if your page already loads require.js -->\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js\" integrity=\"sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=\" crossorigin=\"anonymous\"></script>\n",
    "<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n",
    "<script type=\"application/vnd.jupyter.widget-state+json\">\n",
    "{\n",
    "    \"version_major\": 2,\n",
    "    \"version_minor\": 0,\n",
    "    \"state\": {}\n",
    "}\n",
    "</script>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\n",
    "# Parallel Analysis - Setup and Run\n",
    "\n",
    "This notebook sets up and runs a parallel analysis on AWS.\n",
    "\n",
    "You can learn more at [RGLab/scamp](https://github.com/RGLab/scamp)\n",
    "\n",
    "The steps are:\n",
    "\n",
    "* Create the code\n",
    "* Configure AWS connection\n",
    "* Configure the data you want to process\n",
    "* Upload the data to AWS (to S3)\n",
    "* Configure the processing (code to run, CPU and memory and storage to use)\n",
    "* Kick off the processing\n",
    "\n",
    "\n",
    "### Step A - Create the Code\n",
    "\n",
    "1. Import the necessary libraries\n",
    "2. Create the functions we'll use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import boto3\n",
    "import os.path\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/1392413/calculating-a-directorys-size-using-python \n",
    "def get_folder_size(local_directory):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(local_directory):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size / 1000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_needed (analysis_size_mb):\n",
    "    cpu_count = 4\n",
    "    if analysis_size_mb > 100:\n",
    "        cpu_count = 8\n",
    "    elif analysis_size_mb > 500:\n",
    "        cpu_count = 16\n",
    "    elif analysis_size_mb > 1000:\n",
    "        cpu_count = 32\n",
    "    return cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_needed (analysis_size_mb, cpu_count):\n",
    "    return 2.0 * cpu_count / 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis /Users/dnambi/Downloads/ExampleAnalysis/aaaa is 78.385391 MB and needs 4 CPU and 2.0 GB of RAM\n",
      "Analysis /Users/dnambi/Downloads/ExampleAnalysis/aaaac is 2.826458 MB and needs 4 CPU and 2.0 GB of RAM\n",
      "Analysis /Users/dnambi/Downloads/ExampleAnalysis/aaab is 439.442129 MB and needs 8 CPU and 4.0 GB of RAM\n",
      "Analysis /Users/dnambi/Downloads/ExampleAnalysis/bbscs is 28.17926 MB and needs 4 CPU and 2.0 GB of RAM\n",
      "{'/Users/dnambi/Downloads/ExampleAnalysis/aaaa': {'size_mb': 78.385391, 'cpu_count': 4, 'mem_gb': 2.0}, '/Users/dnambi/Downloads/ExampleAnalysis/aaaac': {'size_mb': 2.826458, 'cpu_count': 4, 'mem_gb': 2.0}, '/Users/dnambi/Downloads/ExampleAnalysis/aaab': {'size_mb': 439.442129, 'cpu_count': 8, 'mem_gb': 4.0}, '/Users/dnambi/Downloads/ExampleAnalysis/bbscs': {'size_mb': 28.17926, 'cpu_count': 4, 'mem_gb': 2.0}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_sizes(parent_directory):\n",
    "    dir_sizes = {}\n",
    "    for analysis_dir in os.listdir(parent_directory):\n",
    "        analysis_dir_path = os.path.join(parent_directory, analysis_dir)\n",
    "        if os.path.isdir(analysis_dir_path):\n",
    "            dir_sizes[analysis_dir_path] = get_folder_size(analysis_dir_path)\n",
    "    return dir_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Users/dnambi/Downloads/ExampleAnalysis/aaaa': 78385391,\n",
       " '/Users/dnambi/Downloads/ExampleAnalysis/aaaac': 2826458,\n",
       " '/Users/dnambi/Downloads/ExampleAnalysis/aaab': 439442129,\n",
       " '/Users/dnambi/Downloads/ExampleAnalysis/bbscs': 28179260}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_directory = '/Users/dnambi/Downloads/ExampleAnalysis'\n",
    "get_analysis_sizes(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://gist.github.com/feelinc/d1f541af4f31d09a2ec3\n",
    "def upload_analysis(input_dir, s3_bucket, s3_prefix, client):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            # construct the full local path\n",
    "            local_path = os.path.join(root, filename)\n",
    "\n",
    "            # construct the full S3 path\n",
    "            relative_path = os.path.relpath(local_path, input_dir)\n",
    "            s3_path = os.path.join(s3_prefix, relative_path)\n",
    "\n",
    "            # relative_path = os.path.relpath(os.path.join(root, filename))\n",
    "\n",
    "            print ('Searching \"%s\" in \"%s\"' % (s3_path, bucket))\n",
    "            try:\n",
    "                client.head_object(Bucket=s3_bucket, Key=s3_path)\n",
    "                print (\"Path found on S3! Skipping %s...\" % s3_path)\n",
    "\n",
    "                # try:\n",
    "                    # client.delete_object(Bucket=bucket, Key=s3_path)\n",
    "                # except:\n",
    "                    # print \"Unable to delete %s...\" % s3_path\n",
    "            except:\n",
    "                print (\"Uploading %s...\" % s3_path)\n",
    "                client.meta.client.upload_file(local_path, bucket, s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching \"dnambi/test/LZLabs/Lab 2 - Review Landing Zone Deployment.docx\" in \"fh-hdc-cytometry-hackathon\"\n",
      "Uploading dnambi/test/LZLabs/Lab 2 - Review Landing Zone Deployment.docx...\n",
      "Searching \"dnambi/test/LZLabs/Lab 3 - Deploy AD and Configure SSO.docx\" in \"fh-hdc-cytometry-hackathon\"\n",
      "Uploading dnambi/test/LZLabs/Lab 3 - Deploy AD and Configure SSO.docx...\n",
      "Searching \"dnambi/test/LZLabs/Lab 3 - Deploy AD and Configure SSO.docx.zip\" in \"fh-hdc-cytometry-hackathon\"\n",
      "Uploading dnambi/test/LZLabs/Lab 3 - Deploy AD and Configure SSO.docx.zip...\n",
      "Searching \"dnambi/test/LZLabs/Lab 4 - Deploy a Member Account.docx\" in \"fh-hdc-cytometry-hackathon\"\n",
      "Uploading dnambi/test/LZLabs/Lab 4 - Deploy a Member Account.docx...\n",
      "Searching \"dnambi/test/LZLabs/Lab 5 - Deploy Centrailzed Logging.docx\" in \"fh-hdc-cytometry-hackathon\"\n",
      "Uploading dnambi/test/LZLabs/Lab 5 - Deploy Centrailzed Logging.docx...\n",
      "Searching \"dnambi/test/LZLabs/Lab 7 - Deleting the Landing Zone.docx\" in \"fh-hdc-cytometry-hackathon\"\n",
      "Uploading dnambi/test/LZLabs/Lab 7 - Deleting the Landing Zone.docx...\n"
     ]
    }
   ],
   "source": [
    "# test it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step B - Configure AWS connection\n",
    "\n",
    "1. Configure AWS account\n",
    "2. Configure AWS credentials (e.g. access key and secret key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ed57e32cd7484da4db588bf292c1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='AWS Profile:', placeholder='default / sandbox')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='default / sandbox',\n",
    "    description='AWS Profile:',\n",
    "    disabled=False\n",
    ")\n",
    "display(profile_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_name = profile_widget.value\n",
    "print(\"{}\".format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/33378422/how-to-choose-an-aws-profile-when-using-boto3-to-connect-to-cloudfront\n",
    "cortex = boto3.session.Session(profile_name='hackathon')\n",
    "s3 = cortex.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the ListBuckets operation: Access Denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-3d5ac450febb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/boto3/resources/collection.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/boto3/resources/collection.py\u001b[0m in \u001b[0;36mpages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                          self._py_operation_name, params)\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_py_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Now that we have a page iterator or single page of results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the ListBuckets operation: Access Denied"
     ]
    }
   ],
   "source": [
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step C - Configure the data you want to process\n",
    "\n",
    "1. Set the input directory\n",
    "2. See the list of analysis, confirm that's corrext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cf4281015546c2acb51510d2bb8ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Directory:', placeholder='/Users/dnambi/hackathon/input')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dir_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='/Users/dnambi/hackathon/input',\n",
    "    description='Directory:',\n",
    "    disabled=False\n",
    ")\n",
    "display(input_dir_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory to load for all analysis is \n"
     ]
    }
   ],
   "source": [
    "input_dir = input_dir_widget.value\n",
    "print(\"The directory to load for all analysis is {}\".format(input_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_analysis = '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_params = {} \n",
    "# key is the analysis folder name\n",
    "# value is a dict of input size, CPU info, memory info, storage info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step D - Upload the data to AWS (to S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb7ef16ae1544b7be7d8b39d7a7b9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='S3 bucket:', placeholder='fh-hdc-egreene-lab-hackathon')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_bucket_widget = widgets.Text(\n",
    "    value='fh-hdc-cytometry-hackathon',\n",
    "    placeholder='',\n",
    "    description='S3 bucket:',\n",
    "    disabled=False\n",
    ")\n",
    "display(s3_bucket_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex = boto3.session.Session(profile_name='hackathon')\n",
    "s3_client = cortex.resource('s3')\n",
    "local_dir = '/Users/dnambi/Downloads/LZLabs'\n",
    "bucket = 'fh-hdc-cytometry-hackathon'\n",
    "prefix = 'dnambi/test/LZLabs'\n",
    "upload_analysis(input_dir=local_dir, s3_bucket=bucket, s3_prefix=prefix, client=s3_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step E - Configure the processing\n",
    "\n",
    "1. Set the code location (GitHub repo)\n",
    "2. Set the startup command\n",
    "3. Configure CPU and memory for each analysis\n",
    "4. Configure storage for each analysis\n",
    "\n",
    "#### Steps E1 and E2 - set GitHub repo and analysis command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5235be4b21ad4e8da2bdc2edf18c5014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='S3 bucket:', placeholder='https://github.com/RGLab/scamp')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "github_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='https://github.com/RGLab/scamp',\n",
    "    description='S3 bucket:',\n",
    "    disabled=False\n",
    ")\n",
    "display(github_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ce95164e3c48b4a7aaf79956d03c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='R command to run', placeholder='Rscript parallel.r --dir /data/input')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_command_widget = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Rscript parallel.r --dir /data/input',\n",
    "    description='R command to run',\n",
    "    disabled=False\n",
    ")\n",
    "display(run_command_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_repo = github_widget.value\n",
    "startup_command = run_command_widget.value\n",
    "\n",
    "print(\"{}\".format())\n",
    "print(\"{}\".format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step E3 - Configure CPU and memory for each analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info for analysis\n",
    "analysis_info = {}\n",
    "for analysis_dir in os.listdir(parent_directory):\n",
    "    analysis_dir_path = os.path.join(parent_directory, analysis_dir)\n",
    "    if os.path.isdir(analysis_dir_path):\n",
    "        folder_size_mb = get_folder_size(analysis_dir_path)\n",
    "        cpu_count_needed = get_cpu_needed(folder_size_mb)\n",
    "        mem_gb_needed = get_memory_needed(folder_size_mb, cpu_count_needed)\n",
    "        print (\"Analysis {} is {} MB and needs {} CPU and {} GB of RAM\".format(analysis_dir_path,folder_size_mb, cpu_count_needed, mem_gb_needed))\n",
    "        analysis_params = {\"size_mb\": folder_size_mb, \"cpu_count\": cpu_count_needed, \"mem_gb\": mem_gb_needed}\n",
    "        analysis_info[analysis_dir_path] = analysis_params\n",
    "print (analysis_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step E4 - Configure storage for each analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step F - Kick off the processing\n",
    "\n",
    "1. Name the batch\n",
    "   * Add the ability to email somene when it's done?\n",
    "2. Kick off the analysis (start the batch)\n",
    "3. Confirm it has started correctly\n",
    "\n",
    "#### Step F1 - Name the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_client = boto3.client('batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID is 2018-12-01-dnambi-test-analysis\n"
     ]
    }
   ],
   "source": [
    "batch_name = 'dnambi-test-analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.DatePicker(\n",
    "    description='Pick a Date',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_start_date = datetime.datetime.now().date()\n",
    "print (\"Batch ID is {}-{}\".format(batch_start_date, batch_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step F2 - Kick off the analysis processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step F3 - Confirm the processing has started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
